### 1.为什么用深层表示

    @1. 深度学习网路的多层隐藏层中，前几层能学习一些低层次的简单特征，后几层能把前面简单的特征结合起来，去学习更加复杂的东西。
        比如刚开始检测到的是边缘信息，而后检测更加细节的东西。
    @2. 深层的网络的隐藏神经元相对较少，隐藏层数目较多，如果浅层的网络需要达到一样的效果则需要指数级增加的神经元数量。

### 2. 为什么深层神经网络难以训练

    @1.梯度消失  原因是网络层次过深以及激活函数选择不当，如sigmoid函数，在深层网络中，如果激活函数的导数小于1，根据链式求导法则，
    靠近输入层的参数的梯度因为乘了很多小于1的数而越来越小，最终就会趋于0。表现为模型无法从训练数据获取参数更新,损失几乎保持不变。

    @2.梯度爆炸  同梯度消失的原因一样，求解损失函数对参数的偏导数时，在梯度的连续乘法中总是遇上很大的绝对值，部分参数的梯度因为乘了
    很多较大的数而变得非常大，导致模型无法收敛。所以梯度爆炸出现的原因也是网络层次过深，或者权值初始化值太大。表现为模型不稳定，训练
    过程中损失出现显著变化或变为Nan(学习率过大也会导致)

    @3.权重矩阵的退化导致模型的有效自由度减少。  什么鬼？

    